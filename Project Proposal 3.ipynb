{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project proposal\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. Please answer the following questions as part of your project proposal.\n",
    "\n",
    "2. Write your answers in the *Markdown* cells of the Jupyter notebook. You don't need to write any code, but if you want to, you may use the *Code* cells.\n",
    "\n",
    "3. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to print the *.ipynb* file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "4. The project proposal is worth 8 points, and is due on **18th April 2023 at 11:59 pm**. \n",
    "\n",
    "5. You must make one submission as a group, and not individually.\n",
    "\n",
    "6. Maintaining a GitHub repository is optional, though encouraged for the project.\n",
    "\n",
    "7. Share the link of your project's GitHub repository [here](https://docs.google.com/spreadsheets/d/1khao3unpj_vsx4kOSg_Zzo77YK1UWL2w73Oa0aAirOo/edit#gid=0) (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "# 1) Team name\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86865c0",
   "metadata": {},
   "source": [
    "**Ashley's Phone is Not Lost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fccc9b",
   "metadata": {},
   "source": [
    "# 2) Member names\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493394d2",
   "metadata": {},
   "source": [
    "Luca Moretti, Kaylee Mo, Nicket Mauskar, Ashley Witarsa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a6528",
   "metadata": {},
   "source": [
    "# 3) Link to the GitHub repository (optional)\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f226524",
   "metadata": {},
   "source": [
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1a490",
   "metadata": {},
   "source": [
    "# 4) Topic\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308603f7",
   "metadata": {},
   "source": [
    "**Predicting individual credit scores based on multiple credit-related predictors using multi-linear regression, decision trees, bagging, random Forests, gradient boosting, and other forms of modeling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403cdfb",
   "metadata": {},
   "source": [
    "# 5) Problem statement\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18d2eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train['Credit_Rating'] = 0\n",
    "train['Credit_Rating'] = np.where(train['Credit_Score'] == 'Good',\n",
    "                          np.random.uniform(670, 730, size=len(train)),\n",
    "                          train['Credit_Rating'])\n",
    "\n",
    "train['Credit_Rating'] = np.where(train['Credit_Score'] == 'Standard',\n",
    "                          np.random.uniform(580, 670, size=len(train)),\n",
    "                          train['Credit_Rating'])\n",
    "\n",
    "train['Credit_Rating'] = np.where(train['Credit_Score'] == 'Poor',\n",
    "                          np.random.uniform(0, 580, size=len(train)),\n",
    "                          train['Credit_Rating'])\n",
    "\n",
    "y_true = train['Credit_Rating']\n",
    "\n",
    "mean_value = np.mean(y_true) \n",
    "y_naive = [mean_value] * len(y_true)\n",
    "\n",
    "naive_rmse = mean_squared_error(y_true, y_naive, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1fd25f",
   "metadata": {},
   "source": [
    "The problem we aim to address in this research project is the accurate prediction/classification of credit scores based on customer credit information and history. Credit scores are a crucial factor in determining an individual's financial health, and lenders heavily rely on them to assess creditworthiness and risk. However, credit score calculations can be complex and multifaceted, taking into account a range of factors such as payment history, outstanding debts, credit utilization, and length of credit history. Our goal is to build a reliable model that can accurately classify credit scores based on customer information, providing lenders with a tool to make more informed decisions and ultimately helping individuals to secure better financial outcomes.\n",
    "\n",
    "As of right now, we have only learned classification models with binary classification. The credit scores are classified into Poor, Standard, and Good on our dataset. We are prepared to assign random credit ratings to those with Poor credit scores (ratings from 300-629), those with Standard (ratings from 630-689), and Good (ratings from 690-719) in order to create regression models and pursue a continuous response; However, we are certain that the decision trees we are learning in class in addition to new material further down the line will allow for classification models with two or more classes. Thus, we expect to use classification rather than regression. \n",
    "\n",
    "If we are to predict using classification, the False Positive Rate (FPR) and True Positive Rate (TPR) are crucial metrics to evaluate the risk of lending money: FPR is a crucial metric for evaluating the risk of lending money to someone who may not be able to repay it, and TPR is an essential metric for evaluating the effectiveness of the credit scoring system in identifying reliable borrowers.  Thus, focusing on these metrics as well as creating an ROC-AUC curve would be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac914e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the naive model: 186.59\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE of the naive model: {naive_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eff2f0",
   "metadata": {},
   "source": [
    "Because we need to learn more about decision trees and more complex modeling forms, we will use regression for now. We used [Investoperdia's FICO socring](https://www.investopedia.com/terms/f/ficoscore.asp) to determine ranges for the \"Poor,\" \"Standard\" and \"Good\" credit score ratings.\n",
    "\n",
    "RMSE will be used as the accuracy measurement for the naive model, which was calculated to be 186.59.  We aim to reduce this, or in the case that we chose to go for classification we will use accuracy score as our metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2d4f2",
   "metadata": {},
   "source": [
    "# 6) Data\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa342a02",
   "metadata": {},
   "source": [
    "Our data source is an open source found on Kaggle. The data provides 100,000 observations, 18 continuous predictors as well as four categorical predictors that will be useful in our prediction of individual credit scores. The response is the column `Credit_Score`. Some of the predictors include `Credit_History_Age`, `new credit`, `Credit_Mix`, `Credit_Utilization_Ratio`, and `Num_of_Delayed_Payment`, amongst many others that will need to be assessed. As it currently stands, we only plan on using one dataset, however this may be subject to change. Linked below is the Kaggle dataset:\n",
    "\n",
    "https://www.kaggle.com/datasets/parisrohan/credit-score-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450286f",
   "metadata": {},
   "source": [
    "# 7) Exisiting solutions\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc91e4",
   "metadata": {},
   "source": [
    "There is one existing solution to our problem. The solution makes use of Logistic Regression, Random Forest, KNeighbors, and Decision Trees. The highest model accuracy is 77.9%, achieved through Random Forest. We plan on improving and tuning these models, and also using MARS, Bagging, Lasso/Ridge/Stepwise selection, and the other models that we will learn in Stat 303-3 to achieve a higher model accuracy than the current solution that is available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a845f",
   "metadata": {},
   "source": [
    "# 8) Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af54c9",
   "metadata": {},
   "source": [
    "**Lenders**: By having a reliable model to classify credit scores, lenders can more accurately assess creditworthiness, reduce the risk of default, and make more informed lending decisions.\n",
    "\n",
    "**Borrowers**: With a better understanding of their creditworthiness, borrowers may be able to secure better loan terms, including lower interest rates, higher credit limits, and more favorable repayment terms.\n",
    "\n",
    "**Credit bureaus**: Accurate credit score models can help credit bureaus improve their credit scoring algorithms, resulting in better credit scores for consumers.\n",
    "\n",
    "**Regulators**: Regulators may benefit from a more accurate credit scoring model by promoting greater transparency and fairness in lending practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c874b4f",
   "metadata": {},
   "source": [
    "# 9) Work-split\n",
    "*(This question is answered for you)*\n",
    "\n",
    "How do you plan to split the project work amongst individual team members?\n",
    "\n",
    "We will learn to develop and tune the following models in the STAT303 sequence:\n",
    "\n",
    "1. MARS\n",
    "\n",
    "2. Decision trees with cost-complexity pruning\n",
    "\n",
    "3. Bagging (Bagging MARS / decision trees)\n",
    "\n",
    "4. Random Forests\n",
    "\n",
    "5. AdaBoost\n",
    "\n",
    "6. Gradient boosting\n",
    "\n",
    "7. XGBoost\n",
    "\n",
    "8. Lasso / Ridge / Stepwise selection \n",
    "\n",
    "Each team member is required to develop and tune at least one of the above models. In the end, the team will combine all the developed models to create a model more accurate than each of the individual models.\n",
    "\n",
    "*(0 points)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
